<div align="center">

# ğŸ“Š Data Pipeline & Analytics  
### Armazenamento, ManipulaÃ§Ã£o e TransformaÃ§Ã£o de Dados

![Banner do Projeto](./Banner.png)

Pipeline de dados desenvolvido para consolidaÃ§Ã£o, tratamento e anÃ¡lise de dados de um marketplace, utilizando conceitos de **ETL**, **Data Warehouse** e **Modelagem Dimensional (Star Schema)**.

</div>

---

## ğŸ“Œ VisÃ£o Geral

Este projeto simula um cenÃ¡rio real de engenharia de dados, no qual informaÃ§Ãµes operacionais dispersas sÃ£o transformadas em uma base analÃ­tica confiÃ¡vel, possibilitando anÃ¡lises estratÃ©gicas e suporte Ã  tomada de decisÃ£o.

---

## â­ Metodologia STAR

### ğŸŸ¢ **Situation â€” SituaÃ§Ã£o**

Um marketplace armazena dados de pedidos, clientes e produtos em diferentes arquivos CSV, oriundos de mÃºltiplos sistemas.  
A ausÃªncia de integraÃ§Ã£o e padronizaÃ§Ã£o dificulta anÃ¡lises histÃ³ricas, gera inconsistÃªncias e limita a extraÃ§Ã£o de insights de negÃ³cio.

---

### ğŸ¯ **Task â€” Tarefa**

Construir um pipeline de dados capaz de:

- Consolidar dados brutos provenientes de mÃºltiplos CSVs  
- Realizar limpeza, tratamento e padronizaÃ§Ã£o  
- Estruturar um **Data Warehouse** em **Star Schema**  
- Permitir anÃ¡lises analÃ­ticas por meio de consultas SQL  

---

### âš™ï¸ **Action â€” AÃ§Ã£o**

As seguintes etapas foram executadas:

- IngestÃ£o dos dados brutos em uma **Staging Area**
- Limpeza, normalizaÃ§Ã£o e deduplicaÃ§Ã£o dos dados
- ImplementaÃ§Ã£o do processo **ETL**
- Modelagem dimensional com tabelas fato e dimensÃµes
- Desenvolvimento de consultas analÃ­ticas

---

## ğŸ—ï¸ Arquitetura da SoluÃ§Ã£o

<div align="center">

![Diagrama de Arquitetura](./assets/diagrama-arquitetura.png)

</div>

### ğŸ”„ Fluxo de Dados

```text
CSVs Brutos
   â†“
Staging Area (Limpeza e Tratamento)
   â†“
Data Warehouse (Star Schema)
   â†“
Dashboard & Insights
